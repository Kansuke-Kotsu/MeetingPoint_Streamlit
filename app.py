import streamlit as st
from pathlib import Path
import tempfile
import datetime as dt
import os

from core_openai import transcribe_audio, generate_minutes as generate_minutes_openai, generate_next_agenda as generate_next_agenda_openai
from core_gemini import transcribe_audio as transcribe_audio_gemini, generate_minutes as generate_minutes_gemini, generate_next_agenda as generate_next_agenda_gemini
from db import MinutesDB
from templates import MINUTES_PROMPT, AGENDA_PROMPT
from audio_utils import convert_m4a_to_mp3, split_mp3_to_chunks

st.set_page_config(page_title="è­°äº‹éŒ²ä½œæˆãƒ„ãƒ¼ãƒ«", page_icon="ğŸ“", layout="wide")
st.title("ğŸ“ è­°äº‹éŒ²ä½œæˆãƒ„ãƒ¼ãƒ«ï¼ˆOpenAI vs Gemini æ¯”è¼ƒï¼‰")

# DB åˆæœŸåŒ–
data_dir = Path(__file__).parent / "data"
data_dir.mkdir(exist_ok=True)
db = MinutesDB(data_dir / "minutes.sqlite3")

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_audio = st.file_uploader("ğŸ¤ ä¼šè­°éŸ³å£°ï¼ˆmp3/m4a ç­‰ï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["mp3", "m4a"])
if not uploaded_audio:
    st.info("ã¾ãšéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# èª­ã¿è¾¼ã¿ï¼†å½¢å¼å¤‰æ›ï¼ˆä¸€åº¦ã ã‘ï¼‰
if not st.session_state.get('audio_converted'):
    with st.spinner("ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ä¸­â€¦"):
        audio_bytes = uploaded_audio.read()
    ext = Path(uploaded_audio.name).suffix.lower()
    if ext == ".m4a":
        with st.spinner("M4Aâ†’MP3å¤‰æ›ä¸­â€¦"):
            try:
                mp3_bytes, mp3_filename = convert_m4a_to_mp3(input_bytes=audio_bytes, original_filename=uploaded_audio.name)
            except Exception as e:
                st.error(f"å¤‰æ›ã‚¨ãƒ©ãƒ¼: {e}")
                st.stop()
        tf = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
        tf.write(mp3_bytes)
        tf.close()
        st.session_state['audio_path'] = Path(tf.name)
        st.success(f"å¤‰æ›å®Œäº†: {mp3_filename}")
    else:
        tf = tempfile.NamedTemporaryFile(delete=False, suffix=ext)
        tf.write(audio_bytes)
        tf.close()
        st.session_state['audio_path'] = Path(tf.name)
    st.session_state['audio_converted'] = True

audio_path = st.session_state['audio_path']
st.audio(str(audio_path), format=f"audio/{audio_path.suffix.replace('.', '')}")

# ä¸€é€£å‡¦ç†ãƒœã‚¿ãƒ³
if st.button("ğŸ”„ æ–‡å­—èµ·ã“ã—ï¼†è­°äº‹éŒ²ä½œæˆï¼ˆOpenAI & Gemini ä¸¦è¡Œï¼‰"):
    # ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ï¼ˆä¸€åº¦ã ã‘ï¼‰
    if not st.session_state.get('split_done'):
        with st.spinner("ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ä¸­â€¦"):
            try:
                cps = split_mp3_to_chunks(audio_path)
            except Exception as e:
                st.error(f"ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã‚¨ãƒ©ãƒ¼: {e}")
                os.remove(audio_path)
                st.stop()
        st.session_state['chunk_paths'] = cps
        st.session_state['split_done'] = True

    # æ–‡å­—èµ·ã“ã—ï¼ˆä¸€åº¦ã ã‘ä¸¡æ–¹ï¼‰
    if not st.session_state.get('transcript_done'):
        full_openai = ""
        full_gemini = ""
        for idx, chunk in enumerate(st.session_state['chunk_paths'], start=1):
            with st.spinner(f"ãƒãƒ£ãƒ³ã‚¯ {idx}/{len(st.session_state['chunk_paths'])} æ–‡å­—èµ·ã“ã—ä¸­â€¦"):
                full_openai += transcribe_audio(chunk).strip() + "\n"
                full_gemini += transcribe_audio_gemini(chunk).strip() + "\n"
            try:
                os.remove(chunk)
            except:
                pass
        os.remove(audio_path)
        st.session_state['transcript_openai'] = full_openai
        st.session_state['transcript_gemini'] = full_gemini
        st.session_state['transcript_done'] = True
        st.success("æ–‡å­—èµ·ã“ã—å®Œäº†ï¼")

    # å„çµæœã®å–å¾—
    transcript_openai = st.session_state.get('transcript_openai', '')
    transcript_gemini = st.session_state.get('transcript_gemini', '')

    # æ–‡å­—èµ·ã“ã—çµæœè¡¨ç¤º
    st.subheader("### æ–‡å­—èµ·ã“ã—çµæœ æ¯”è¼ƒ")
    col_t1, col_t2 = st.columns(2)
    with col_t1:
        st.markdown("**OpenAI Whisper**")
        st.text_area("OpenAI æ–‡å­—èµ·ã“ã—", value=transcript_openai, height=300, key="trans_openai")
    with col_t2:
        st.markdown("**Gemini Whisper**")
        st.text_area("Gemini æ–‡å­—èµ·ã“ã—", value=transcript_gemini, height=300, key="trans_gemini")

    # ä¸¦è¡Œç”Ÿæˆ
    with st.spinner("è­°äº‹éŒ²ãƒ»ã‚¢ã‚¸ã‚§ãƒ³ãƒ€ç”Ÿæˆä¸­â€¦"):
        # OpenAIç‰ˆ
        minutes_oa = generate_minutes_openai(transcript_openai, MINUTES_PROMPT)
        agenda_oa = generate_next_agenda_openai(transcript_openai, AGENDA_PROMPT, db)
        # Geminiç‰ˆ
        minutes_gm = generate_minutes_gemini(transcript_gemini, MINUTES_PROMPT)
        agenda_gm = generate_next_agenda_gemini(transcript_gemini, AGENDA_PROMPT, db)

    # è­°äº‹éŒ²ãƒ»ã‚¢ã‚¸ã‚§ãƒ³ãƒ€è¡¨ç¤º
    st.subheader("### è­°äº‹éŒ²ï¼†æ¬¡å›ã‚¢ã‚¸ã‚§ãƒ³ãƒ€ æ¯”è¼ƒ")
    col1, col2 = st.columns(2)
    with col1:
        st.subheader("ğŸ“„ OpenAI ChatGPT è­°äº‹éŒ²")
        st.markdown(minutes_oa, unsafe_allow_html=True)
        st.subheader("ğŸ—“ï¸ OpenAI æ¬¡å›ã‚¢ã‚¸ã‚§ãƒ³ãƒ€")
        st.markdown(agenda_oa, unsafe_allow_html=True)
        db.save_minutes(f"OpenAI {dt.datetime.now():%Y-%m-%d %H:%M}", transcript_openai, minutes_oa)
    with col2:
        st.subheader("ğŸ“„ Gemini è­°äº‹éŒ²")
        st.markdown(minutes_gm, unsafe_allow_html=True)
        st.subheader("ğŸ—“ï¸ Gemini æ¬¡å›ã‚¢ã‚¸ã‚§ãƒ³ãƒ€")
        st.markdown(agenda_gm, unsafe_allow_html=True)
        db.save_minutes(f"Gemini {dt.datetime.now():%Y-%m-%d %H:%M}", transcript_gemini, minutes_gm)

# éå»ã®è­°äº‹éŒ²
st.divider()
st.subheader("ğŸ“š éå»ã®è­°äº‹éŒ²")
for rec in db.fetch_all_minutes():
    with st.expander(rec["title"]):
        st.markdown(rec["minutes_md"], unsafe_allow_html=True)
