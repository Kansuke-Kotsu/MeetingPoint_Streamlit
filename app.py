import streamlit as st
from pathlib import Path
import tempfile
import datetime as dt
import os
import time

from core_openai import transcribe_audio, generate_minutes as generate_minutes_openai, generate_next_agenda as generate_next_agenda_openai
from core_gemini import transcribe_audio as transcribe_audio_gemini, generate_minutes as generate_minutes_gemini, generate_next_agenda as generate_next_agenda_gemini
from db import MinutesDB
from templates import MINUTES_PROMPT, AGENDA_PROMPT
from audio_utils import convert_m4a_to_mp3, split_mp3_to_chunks

st.set_page_config(page_title="è­°äº‹éŒ²ä½œæˆãƒ„ãƒ¼ãƒ«", page_icon="ğŸ“", layout="wide")
st.title("ğŸ“ è­°äº‹éŒ²ä½œæˆãƒ„ãƒ¼ãƒ«ï¼ˆOpenAI vs Gemini æ¯”è¼ƒãƒ»ã‚¿ãƒ–è¡¨ç¤ºï¼‰")

# DB åˆæœŸåŒ–
data_dir = Path(__file__).parent / "data"
data_dir.mkdir(exist_ok=True)
db = MinutesDB(data_dir / "minutes.sqlite3")

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded_audio = st.file_uploader("ğŸ¤ ä¼šè­°éŸ³å£°ï¼ˆmp3/m4a ç­‰ï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["mp3", "m4a"])
if not uploaded_audio:
    st.info("ã¾ãšéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
    st.stop()

# å¤‰æ›ï¼ˆä¸€åº¦ã ã‘ï¼‰
if not st.session_state.get('audio_converted'):
    with st.spinner("ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ï¼†å¤‰æ›ä¸­â€¦"):
        audio_bytes = uploaded_audio.read()
        ext = Path(uploaded_audio.name).suffix.lower()
        if ext == ".m4a":
            mp3_bytes, _ = convert_m4a_to_mp3(input_bytes=audio_bytes, original_filename=uploaded_audio.name)
            suffix = ".mp3"
        else:
            mp3_bytes = audio_bytes
            suffix = ext
        tf = tempfile.NamedTemporaryFile(delete=False, suffix=suffix)
        tf.write(mp3_bytes)
        tf.close()
        st.session_state['audio_path'] = Path(tf.name)
        st.session_state['audio_converted'] = True

audio_path = st.session_state['audio_path']
st.audio(str(audio_path), format=f"audio/{audio_path.suffix.replace('.', '')}")

# å®Ÿè¡Œãƒœã‚¿ãƒ³
if st.button("ğŸš€ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†é–‹å§‹ï¼ˆOpenAI & Geminiï¼‰"):
    # å…¨ä½“é€²æ—ãƒãƒ¼
    total_steps = 2
    overall_progress = st.sidebar.progress(0)

    # ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²
    st.sidebar.write("## ã‚¹ãƒ†ãƒƒãƒ—1: ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²")
    try:
        chunk_paths = split_mp3_to_chunks(audio_path)
        st.sidebar.success(f"{len(chunk_paths)} å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ä½œæˆã—ã¾ã—ãŸ")
    except Exception as e:
        st.sidebar.error(f"ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²ã‚¨ãƒ©ãƒ¼: {e}")
        st.stop()
    overall_progress.progress(1 / total_steps)

    # ä¸¦åˆ—é€²æ—ãƒãƒ¼
    st.sidebar.write("## ã‚¹ãƒ†ãƒƒãƒ—2: æ–‡å­—èµ·ã“ã—ï¼†ç”Ÿæˆé€²æ—")
    prog_oa = st.sidebar.progress(0)
    prog_gm = st.sidebar.progress(0)

    # å„ç¨®ã‚¿ã‚¤ãƒãƒ¼
    transcripts_oa, transcripts_gm = [], []
    t_oa = t_gm = 0.0
    count = len(chunk_paths)

    # æ–‡å­—èµ·ã“ã—
    for idx, chunk in enumerate(chunk_paths, start=1):
        start = time.time()
        txt_oa = transcribe_audio(chunk).strip()
        t_oa += time.time() - start
        start = time.time()
        txt_gm = transcribe_audio_gemini(chunk).strip()
        t_gm += time.time() - start
        transcripts_oa.append(txt_oa)
        transcripts_gm.append(txt_gm)
        prog_oa.progress(idx / count)
        prog_gm.progress(idx / count)
        os.remove(chunk)
    os.remove(audio_path)

    overall_progress.progress(2 / total_steps)
    st.sidebar.success("ã™ã¹ã¦ã®æ–‡å­—èµ·ã“ã—ãŒå®Œäº†ã—ã¾ã—ãŸï¼")

    # çµ±åˆãƒ†ã‚­ã‚¹ãƒˆ
    transcript_openai = "\n".join(transcripts_oa)
    transcript_gemini = "\n".join(transcripts_gm)

    # ã‚¿ãƒ–è¡¨ç¤º
    tabs = st.tabs(["OpenAI", "Gemini"])

    # OpenAIã‚¿ãƒ–
    with tabs[0]:
        st.header("OpenAI çµæœ")
        st.metric("Whisper æ™‚é–“", f"{t_oa:.1f}s")
        # è­°äº‹éŒ²ç”Ÿæˆ
        with st.spinner("OpenAI: è­°äº‹éŒ²ç”Ÿæˆä¸­â€¦"):
            start = time.time(); minutes_oa = generate_minutes_openai(transcript_openai, MINUTES_PROMPT); dt1 = time.time() - start
        st.metric("Minutes æ™‚é–“", f"{dt1:.1f}s")
        # ã‚¢ã‚¸ã‚§ãƒ³ãƒ€ç”Ÿæˆ
        with st.spinner("OpenAI: ã‚¢ã‚¸ã‚§ãƒ³ãƒ€ç”Ÿæˆä¸­â€¦"):
            start = time.time(); agenda_oa = generate_next_agenda_openai(transcript_openai, AGENDA_PROMPT, db); dt2 = time.time() - start
        st.metric("Agenda æ™‚é–“", f"{dt2:.1f}s")
        st.subheader("æ–‡å­—èµ·ã“ã—çµæœ")
        st.text_area("", transcript_openai, height=200)
        st.subheader("è­°äº‹éŒ²")
        st.markdown(minutes_oa, unsafe_allow_html=True)
        st.subheader("æ¬¡å›ã‚¢ã‚¸ã‚§ãƒ³ãƒ€")
        st.markdown(agenda_oa, unsafe_allow_html=True)
        db.save_minutes(f"OpenAI {dt.datetime.now():%Y-%m-%d %H:%M}", transcript_openai, minutes_oa)

    # Geminiã‚¿ãƒ–
    with tabs[1]:
        st.header("Gemini çµæœ")
        st.metric("Whisper æ™‚é–“", f"{t_gm:.1f}s")
        with st.spinner("Gemini: è­°äº‹éŒ²ç”Ÿæˆä¸­â€¦"):
            start = time.time(); minutes_gm = generate_minutes_gemini(transcript_gemini, MINUTES_PROMPT); dt3 = time.time() - start
        st.metric("Minutes æ™‚é–“", f"{dt3:.1f}s")
        with st.spinner("Gemini: ã‚¢ã‚¸ã‚§ãƒ³ãƒ€ç”Ÿæˆä¸­â€¦"):
            start = time.time(); agenda_gm = generate_next_agenda_gemini(transcript_gemini, AGENDA_PROMPT, db); dt4 = time.time() - start
        st.metric("Agenda æ™‚é–“", f"{dt4:.1f}s")
        st.subheader("æ–‡å­—èµ·ã“ã—çµæœ")
        st.text_area("", transcript_gemini, height=200)
        st.subheader("è­°äº‹éŒ²")
        st.markdown(minutes_gm, unsafe_allow_html=True)
        st.subheader("æ¬¡å›ã‚¢ã‚¸ã‚§ãƒ³ãƒ€")
        st.markdown(agenda_gm, unsafe_allow_html=True)
        db.save_minutes(f"Gemini {dt.datetime.now():%Y-%m-%d %H:%M}", transcript_gemini, minutes_gm)

# éå»ã®è­°äº‹éŒ²
st.divider()
st.subheader("ğŸ“š éå»ã®è­°äº‹éŒ²")
for rec in db.fetch_all_minutes():
    with st.expander(rec["title"]):
        st.markdown(rec["minutes_md"], unsafe_allow_html=True)
